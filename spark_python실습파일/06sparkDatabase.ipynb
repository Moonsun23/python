{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d4738d-d231-416b-9e65-2b480ee93f00",
   "metadata": {},
   "source": [
    "## SparkJDBC\n",
    "+ MariaDB나 Oracle에 저장된 테이블을 불러와서\n",
    "분석을 하려면 pyspark 실행시 JDBC드라이버를 지정해야 함\n",
    "+ pyspark --driver-class-path '사용할 jdbc드라이버'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163e414d-d0b0-44b0-9fba-54fb883484a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mariadb 접속정보\n",
    "url = 'jdbc:mysql://bigdata.c8hdgnwsefiu.ap-northeast-2.rds.amazonaws.com:3306/bigdata'\n",
    "uid = 'admin'\n",
    "pwd = 'Bigdata_2023'\n",
    "db = 'bigdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a74d03-01ec-4820-bae2-368a02ffe91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparkSQL을 위한 스파크 세션 생성\n",
    "spark = SparkSession.builder.master('app').appName('sparkJDBC').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2f902d-d185-4943-b876-51a25604eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read.format('jdbc').options(접속정보)\n",
    "emp = spark.read.format('jdbc')\\\n",
    "    .options(url = url, user=uid, password=pwd, dbtable='EMPLOYEES')\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab2da37-63e8-4055-8f2b-809bc18e6e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EMPLOYEE_ID: integer (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- EMAIL: string (nullable = true)\n",
      " |-- PHONE_NUMBER: string (nullable = true)\n",
      " |-- HIRE_DATE: string (nullable = true)\n",
      " |-- JOB_ID: string (nullable = true)\n",
      " |-- SALARY: double (nullable = true)\n",
      " |-- COMMISSION_PCT: double (nullable = true)\n",
      " |-- MANAGER_ID: integer (nullable = true)\n",
      " |-- DEPARTMENT_ID: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2563a9e8-c421-4197-859c-0f5fddc54ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|FIRST_NAME|\n",
      "+----------+\n",
      "|    Steven|\n",
      "|     Neena|\n",
      "|       Lex|\n",
      "| Alexander|\n",
      "|     Bruce|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "emp.select('FIRST_NAME').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca70f35-c0a8-4221-aea2-aca0c9de73f4",
   "metadata": {},
   "source": [
    "### spark jar 디렉토리를 이용해서 database 접속하기\n",
    "+ /usr/share/spark/jars 에 mariadb-java-client-2.7.2.jar, mysql-connector-java-5.1.49-bin.jar, ojdbc8.jar 복사해 줌\n",
    "   - 실행중인 pyspark 중지시킴\n",
    "   - cp   /home/hadoop/jdbc/*.jar   /usr/share/spark/jars/  (관리자 계정)\n",
    "   - chown   hadoop:hadoop  -R  /usr/share/spark\n",
    "   - pyspark 다시 실행"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
